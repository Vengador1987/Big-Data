{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:27:51.059294Z","iopub.execute_input":"2022-05-09T10:27:51.059899Z","iopub.status.idle":"2022-05-09T10:28:44.290750Z","shell.execute_reply.started":"2022-05-09T10:27:51.059784Z","shell.execute_reply":"2022-05-09T10:28:44.289645Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"`Documentacion:` http://spark.apache.org/docs/latest/ml-features.html","metadata":{}},{"cell_type":"code","source":"from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"LinearRegression\").getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:28:53.962493Z","iopub.execute_input":"2022-05-09T10:28:53.963482Z","iopub.status.idle":"2022-05-09T10:29:00.883980Z","shell.execute_reply.started":"2022-05-09T10:28:53.963426Z","shell.execute_reply":"2022-05-09T10:29:00.882781Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## `Transformaciones`","metadata":{}},{"cell_type":"code","source":"df = spark.read.csv(path = \"../input/regresin-lineal/fake_customers.csv\", \n                    inferSchema = True, header = True)\n\ndf.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:29:28.119320Z","iopub.execute_input":"2022-05-09T10:29:28.119706Z","iopub.status.idle":"2022-05-09T10:29:34.791447Z","shell.execute_reply.started":"2022-05-09T10:29:28.119664Z","shell.execute_reply":"2022-05-09T10:29:34.790238Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## `StringIndexer`\n\nPara transformar los valores categoricos a numericos.","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.feature import StringIndexer\n\nindexer1 = StringIndexer(inputCol = \"Group\",\n                         outputCol = \"GroupIndex\")\n\nindexed1 = indexer1.fit(df).transform(df)\n\nindexed1.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:30:45.944265Z","iopub.execute_input":"2022-05-09T10:30:45.944653Z","iopub.status.idle":"2022-05-09T10:30:48.187087Z","shell.execute_reply.started":"2022-05-09T10:30:45.944608Z","shell.execute_reply":"2022-05-09T10:30:48.185967Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"indexer2 = StringIndexer(inputCol = \"Name\",\n                         outputCol = \"NameIndex\")\n\nindexed2 = indexer2.fit(indexed1).transform(indexed1)\n\nindexed2.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:31:14.293188Z","iopub.execute_input":"2022-05-09T10:31:14.293567Z","iopub.status.idle":"2022-05-09T10:31:15.039152Z","shell.execute_reply.started":"2022-05-09T10:31:14.293532Z","shell.execute_reply":"2022-05-09T10:31:15.038136Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## `VectorIndexer`\nPara transformar los datos a un vector denso. Esto ultimo es obligatorio para los modelos de ML en PySpark.","metadata":{"execution":{"iopub.execute_input":"2021-11-28T20:16:34.660394Z","iopub.status.busy":"2021-11-28T20:16:34.660043Z","iopub.status.idle":"2021-11-28T20:16:34.665394Z","shell.execute_reply":"2021-11-28T20:16:34.664291Z","shell.execute_reply.started":"2021-11-28T20:16:34.660358Z"}}},{"cell_type":"code","source":"from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(inputCols = [\"Phone\", \"GroupIndex\", \"NameIndex\"],\n                            outputCol = \"features\")\n\noutput = assembler.transform(indexed2)\n\noutput.select([\"Phone\", \"GroupIndex\", \"NameIndex\", \"features\"]).show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:36:26.317685Z","iopub.execute_input":"2022-05-09T10:36:26.319041Z","iopub.status.idle":"2022-05-09T10:36:27.036464Z","shell.execute_reply.started":"2022-05-09T10:36:26.318973Z","shell.execute_reply":"2022-05-09T10:36:27.035325Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# `LinearRegression`","metadata":{}},{"cell_type":"code","source":"from pyspark.ml.regression import LinearRegression","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:36:37.934123Z","iopub.execute_input":"2022-05-09T10:36:37.934560Z","iopub.status.idle":"2022-05-09T10:36:37.940447Z","shell.execute_reply.started":"2022-05-09T10:36:37.934519Z","shell.execute_reply":"2022-05-09T10:36:37.939312Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data = spark.read.format(\"libsvm\").load(\"../input/regresin-lineal/sample_linear_regression_data.txt\")\n\ndata.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:36:54.568251Z","iopub.execute_input":"2022-05-09T10:36:54.569340Z","iopub.status.idle":"2022-05-09T10:36:55.298548Z","shell.execute_reply.started":"2022-05-09T10:36:54.569273Z","shell.execute_reply":"2022-05-09T10:36:55.297476Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Este es el formato que Spark usa para hacer ML, dos columnas, una llamada \"label\" y otra de \"features\", que serían \"y\" y \"X\" respectivamente.\n\nLa columna \"label\" o \"y\" debe ser una columna numerica, al igual que cuando haciamos modelos de SciKit-Learn.\n\nLa columna \"features\" o \"X\" esta formada por vectores , estos vectores son los elementos agrupados de las columnas iniciales.","metadata":{}},{"cell_type":"code","source":"# Inicializamos el modelo\nlr = LinearRegression(featuresCol = \"features\",\n                      labelCol = \"label\",\n                      predictionCol = \"prediction\")\n\n# Nota: si en el DataFrame las columnas tienen otros nombres podemos decirle al modelo que trabaje con esos nombres\n# Por convencion \"X\" se llama \"features\", \"y\" se llama \"label\" y las predicciones se llaman \"prediction\"\n# Y esos son los valores por defecto de los modelo de ML.\n\n# Entrenamos el modelo \nmodel = lr.fit(data)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:38:53.593153Z","iopub.execute_input":"2022-05-09T10:38:53.593572Z","iopub.status.idle":"2022-05-09T10:38:55.017060Z","shell.execute_reply.started":"2022-05-09T10:38:53.593536Z","shell.execute_reply":"2022-05-09T10:38:55.016173Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Podemos imprimir los coeficientes de la regresion\nprint(\"Coeficientes: {}\".format(str(model.coefficients)))\nprint(\"\\n\")\nprint(\"Intercepcion:{}\".format(str(model.intercept)))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:39:51.956038Z","iopub.execute_input":"2022-05-09T10:39:51.956748Z","iopub.status.idle":"2022-05-09T10:39:51.992863Z","shell.execute_reply.started":"2022-05-09T10:39:51.956697Z","shell.execute_reply":"2022-05-09T10:39:51.991956Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## `Summary`","metadata":{}},{"cell_type":"code","source":"# El modelo tiene el atributo .summary\n# Este summary se hace sobre el set de entrenamiento y calcula las métricas del modelo\nsummary = model.summary","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:40:42.869313Z","iopub.execute_input":"2022-05-09T10:40:42.869665Z","iopub.status.idle":"2022-05-09T10:40:42.877394Z","shell.execute_reply.started":"2022-05-09T10:40:42.869628Z","shell.execute_reply":"2022-05-09T10:40:42.876426Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"summary.residuals.show()\n# .residuals es la diferencia entre el valor real y el valor predicho \n\nprint(\"RMSE: {}\".format(summary.rootMeanSquaredError))\nprint(\"r2: {}\".format(summary.r2))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:40:48.529072Z","iopub.execute_input":"2022-05-09T10:40:48.529441Z","iopub.status.idle":"2022-05-09T10:40:48.834172Z","shell.execute_reply.started":"2022-05-09T10:40:48.529399Z","shell.execute_reply":"2022-05-09T10:40:48.833278Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## `Train/Test Split`\n\nNo existe la función train_test_split... Pero los objetos DataFrames de Spark tienen un metodo que hace lo mismo que train_test_split.","metadata":{}},{"cell_type":"code","source":"data.show(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:43:12.674310Z","iopub.execute_input":"2022-05-09T10:43:12.675330Z","iopub.status.idle":"2022-05-09T10:43:12.835590Z","shell.execute_reply.started":"2022-05-09T10:43:12.675271Z","shell.execute_reply":"2022-05-09T10:43:12.834649Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# .randomSplit()\n\ntrain, test = data.randomSplit(weights = [0.7, 0.3], seed = 42)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:43:13.886090Z","iopub.execute_input":"2022-05-09T10:43:13.886466Z","iopub.status.idle":"2022-05-09T10:43:13.916439Z","shell.execute_reply.started":"2022-05-09T10:43:13.886433Z","shell.execute_reply":"2022-05-09T10:43:13.915312Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train.show(3)\n\ntest.show(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:43:27.334877Z","iopub.execute_input":"2022-05-09T10:43:27.335741Z","iopub.status.idle":"2022-05-09T10:43:27.868911Z","shell.execute_reply.started":"2022-05-09T10:43:27.335676Z","shell.execute_reply":"2022-05-09T10:43:27.867900Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = lr.fit(train)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:43:52.053830Z","iopub.execute_input":"2022-05-09T10:43:52.054202Z","iopub.status.idle":"2022-05-09T10:43:52.710563Z","shell.execute_reply.started":"2022-05-09T10:43:52.054166Z","shell.execute_reply":"2022-05-09T10:43:52.709333Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"y_hat = model.evaluate(test)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:44:04.227773Z","iopub.execute_input":"2022-05-09T10:44:04.228094Z","iopub.status.idle":"2022-05-09T10:44:04.490005Z","shell.execute_reply.started":"2022-05-09T10:44:04.228063Z","shell.execute_reply":"2022-05-09T10:44:04.488927Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y_hat.predictions.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:44:05.237359Z","iopub.execute_input":"2022-05-09T10:44:05.237716Z","iopub.status.idle":"2022-05-09T10:44:05.427942Z","shell.execute_reply.started":"2022-05-09T10:44:05.237676Z","shell.execute_reply":"2022-05-09T10:44:05.426934Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"y_hat.residuals.show()\nprint(\"RMSE: {}\".format(y_hat.rootMeanSquaredError))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:45:51.333803Z","iopub.execute_input":"2022-05-09T10:45:51.334183Z","iopub.status.idle":"2022-05-09T10:45:51.570356Z","shell.execute_reply.started":"2022-05-09T10:45:51.334149Z","shell.execute_reply":"2022-05-09T10:45:51.569324Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Hasta aquí llegaría el modelo, ahora vamos a ver como hacer predicciones de datos nuevos.\n\nVamos a trabajar con la columna de \"features\" de test, así solo nos quedamos con \"X\" y no sabemos el valor de \"y\".","metadata":{}},{"cell_type":"code","source":"nueva_data = test.select(\"features\")\nnueva_data.show(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:46:58.260261Z","iopub.execute_input":"2022-05-09T10:46:58.260649Z","iopub.status.idle":"2022-05-09T10:46:58.465391Z","shell.execute_reply.started":"2022-05-09T10:46:58.260607Z","shell.execute_reply":"2022-05-09T10:46:58.464319Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# En lugar de usar .evaluate() vamos a usar .transform() y esto nos retorna un nuevo DataFrame\ny_hat = model.transform(nueva_data)\ny_hat.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T10:47:11.094832Z","iopub.execute_input":"2022-05-09T10:47:11.095813Z","iopub.status.idle":"2022-05-09T10:47:11.342368Z","shell.execute_reply.started":"2022-05-09T10:47:11.095751Z","shell.execute_reply":"2022-05-09T10:47:11.341179Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## `Guardar el modelo`","metadata":{}},{"cell_type":"code","source":"model.save(path = \"modelo.model\")","metadata":{"execution":{"iopub.execute_input":"2021-11-29T12:57:47.213277Z","iopub.status.busy":"2021-11-29T12:57:47.212967Z","iopub.status.idle":"2021-11-29T12:57:48.593236Z","shell.execute_reply":"2021-11-29T12:57:48.592464Z","shell.execute_reply.started":"2021-11-29T12:57:47.213234Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################################################################################################################","metadata":{},"execution_count":null,"outputs":[]}]}